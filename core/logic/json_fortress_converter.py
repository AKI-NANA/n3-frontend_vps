#!/usr/bin/env python3
"""
N3 Empire OS - JSONè¦å¡åŒ–å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
=========================================
Version: 1.0.0
Purpose: n8nãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼JSONã‚’ä¸€æ‹¬è¦å¡åŒ–

å¤‰æ›å†…å®¹:
1. HMACç½²åæ¤œè¨¼ãƒãƒ¼ãƒ‰è‡ªå‹•æŒ¿å…¥ï¼ˆå…¨Webhookç›´å¾Œï¼‰
2. ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ â†’ ç’°å¢ƒå¤‰æ•°åŒ–
3. è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ â†’ Python APIå‘¼ã³å‡ºã—ã«ç½®æ›
4. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šé©ç”¨
5. ãƒ­ã‚°/å±¥æ­´è‡ªå‹•å‰Šé™¤è¨­å®š

ä½¿ç”¨æ–¹æ³•:
  # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›
  python json_fortress_converter.py input.json output.json
  
  # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€æ‹¬å¤‰æ›
  python json_fortress_converter.py --batch /path/to/PRODUCTION /path/to/ENHANCED
"""

import os
import sys
import json
import re
import argparse
import hashlib
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime
import copy


# ======================
# å¤‰æ›è¨­å®š
# ======================

# ç’°å¢ƒå¤‰æ•°åŒ–å¯¾è±¡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
ENV_VAR_PATTERNS = [
    # URLãƒ‘ã‚¿ãƒ¼ãƒ³
    (r'http://160\.16\.120\.186:(\d+)', r'{{ $env.VPS_URL }}:\1'),
    (r'https://zdzfpucdyxdlavkgrvil\.supabase\.co', r'{{ $env.SUPABASE_URL }}'),
    (r'https://api\.chatwork\.com', r'{{ $env.CHATWORK_API_URL }}'),
    
    # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸèªè¨¼æƒ…å ±ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒï¼‰
    (r'"X-ChatWorkToken"[:\s]*"[^"]+"', '"X-ChatWorkToken": "{{ $env.CHATWORK_API_KEY }}"'),
    (r'"apikey"[:\s]*"eyJ[^"]+"', '"apikey": "{{ $env.SUPABASE_ANON_KEY }}"'),
    
    # n8nå†…éƒ¨å‚ç…§
    (r'\{\{.*?\$env\.N3_API_URL.*?\}\}', '{{ $env.N3_API_URL }}'),
    (r'\{\{.*?\$env\.GATEWAY_URL.*?\}\}', '{{ $env.N3_API_URL }}'),
]

# Python APIç½®æ›å¯¾è±¡ã®ãƒãƒ¼ãƒˆ
PYTHON_MIGRATION_MARKER = '[PYTHON_MIGRATION_CANDIDATE]'

# HMACæ¤œè¨¼ãƒãƒ¼ãƒ‰ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
HMAC_VERIFY_NODE_TEMPLATE = {
    "parameters": {
        "jsCode": """// N3 HMACç½²åæ¤œè¨¼ï¼ˆè¦å¡åŒ–è‡ªå‹•æŒ¿å…¥ï¼‰
const headers = $input.first().json.headers || {};
const body = $input.first().json.body || $input.first().json;

const signature = headers['x-n3-signature'] || headers['X-N3-Signature'] || '';
const timestamp = headers['x-n3-timestamp'] || headers['X-N3-Timestamp'] || '';

// ç½²åãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯æ¤œè¨¼
if (signature && timestamp) {
  const secret = $env.N3_HMAC_SECRET;
  if (!secret) {
    return [{ json: { error: true, message: 'N3_HMAC_SECRET ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®š', code: 'CONFIG_ERROR' } }];
  }
  
  // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ¤œè¨¼ï¼ˆ5åˆ†ä»¥å†…ï¼‰
  const ts = parseInt(timestamp, 10);
  const now = Math.floor(Date.now() / 1000);
  if (Math.abs(now - ts) > 300) {
    return [{ json: { error: true, message: 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æœŸé™åˆ‡ã‚Œ', code: 'TIMESTAMP_EXPIRED' } }];
  }
  
  // ç½²åæ¤œè¨¼ï¼ˆå¤–éƒ¨APIã¸å§”è­²ï¼‰
  try {
    const verifyUrl = $env.PRICING_ENGINE_URL || 'http://localhost:8000';
    const payload = JSON.stringify(body);
    const response = await fetch(`${verifyUrl}/verify-signature`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ payload, signature, timestamp })
    });
    const result = await response.json();
    if (!result.valid) {
      return [{ json: { error: true, message: 'ç½²åæ¤œè¨¼å¤±æ•—: ' + (result.error || ''), code: 'INVALID_SIGNATURE' } }];
    }
  } catch (e) {
    // ç½²åæ¤œè¨¼APIãŒåˆ©ç”¨ä¸å¯ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆé–‹ç™ºç’°å¢ƒï¼‰
    console.log('ç½²åæ¤œè¨¼ã‚¹ã‚­ãƒƒãƒ—: ' + e.message);
  }
}

// ãƒ‘ã‚¹ã‚¹ãƒ«ãƒ¼
return $input.all();"""
    },
    "type": "n8n-nodes-base.code",
    "typeVersion": 2,
    "notes": "[FORTRESS_AUTO_INSERTED] HMACç½²åæ¤œè¨¼"
}

# è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ç½®æ›ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
PYTHON_API_CALL_TEMPLATE = {
    "parameters": {
        "method": "POST",
        "url": "={{ $env.PRICING_ENGINE_URL || 'http://localhost:8000' }}/calculate",
        "sendHeaders": True,
        "headerParameters": {
            "parameters": [
                {"name": "Content-Type", "value": "application/json"},
                {"name": "x-n3-signature", "value": "={{ $execution.customData?.hmacSignature || '' }}"},
                {"name": "x-n3-timestamp", "value": "={{ $execution.customData?.hmacTimestamp || '' }}"}
            ]
        },
        "sendBody": True,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify($json) }}",
        "options": {"timeout": 30000}
    },
    "type": "n8n-nodes-base.httpRequest",
    "typeVersion": 4.2,
    "continueOnFail": True,
    "notes": "[FORTRESS_MIGRATED] Python APIå‘¼ã³å‡ºã—"
}


# ======================
# å¤‰æ›é–¢æ•°
# ======================

def generate_node_id(prefix: str = 'fortress') -> str:
    """ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒãƒ¼ãƒ‰IDã‚’ç”Ÿæˆ"""
    import uuid
    return f'{prefix}_{uuid.uuid4().hex[:8]}'


def find_webhook_nodes(workflow: Dict) -> List[Dict]:
    """Webhookãƒãƒ¼ãƒ‰ã‚’æ¤œç´¢"""
    nodes = workflow.get('nodes', [])
    return [n for n in nodes if n.get('type', '').endswith('.webhook')]


def find_connections_from_node(workflow: Dict, node_name: str) -> List[Dict]:
    """æŒ‡å®šãƒãƒ¼ãƒ‰ã‹ã‚‰ã®æ¥ç¶šã‚’æ¤œç´¢"""
    connections = workflow.get('connections', {})
    return connections.get(node_name, {}).get('main', [[]])[0]


def insert_hmac_verify_node(workflow: Dict) -> Dict:
    """Webhookç›´å¾Œã«HMACæ¤œè¨¼ãƒãƒ¼ãƒ‰ã‚’æŒ¿å…¥"""
    workflow = copy.deepcopy(workflow)
    nodes = workflow.get('nodes', [])
    connections = workflow.get('connections', {})
    
    webhook_nodes = find_webhook_nodes(workflow)
    
    for webhook in webhook_nodes:
        webhook_name = webhook.get('name', '')
        
        # æ—¢ã«æ¤œè¨¼ãƒãƒ¼ãƒ‰ãŒæŒ¿å…¥æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
        existing = [n for n in nodes if '[FORTRESS_AUTO_INSERTED]' in (n.get('notes', '') or '')]
        if any(webhook_name in str(c) for c in connections.get(n.get('name', ''), {}) for n in existing):
            continue
        
        # å…ƒã®æ¥ç¶šå…ˆã‚’å–å¾—
        original_targets = connections.get(webhook_name, {}).get('main', [[]])[0]
        
        if not original_targets:
            continue
        
        # HMACæ¤œè¨¼ãƒãƒ¼ãƒ‰ã‚’ä½œæˆ
        verify_node = copy.deepcopy(HMAC_VERIFY_NODE_TEMPLATE)
        verify_node_id = generate_node_id('hmac_verify')
        verify_node_name = f'ğŸ” ç½²åæ¤œè¨¼ ({webhook_name})'
        verify_node['id'] = verify_node_id
        verify_node['name'] = verify_node_name
        
        # Webhookã®positionæƒ…å ±ãŒã‚ã‚Œã°ã€å°‘ã—ä¸‹ã«é…ç½®
        if 'position' in webhook:
            pos = webhook['position']
            verify_node['position'] = [pos[0] + 200, pos[1]]
        
        nodes.append(verify_node)
        
        # æ¥ç¶šã‚’æ›´æ–°
        # Webhook â†’ æ¤œè¨¼ãƒãƒ¼ãƒ‰ â†’ å…ƒã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
        connections[webhook_name] = {
            'main': [[{'node': verify_node_name, 'type': 'main', 'index': 0}]]
        }
        connections[verify_node_name] = {
            'main': [original_targets]
        }
    
    workflow['nodes'] = nodes
    workflow['connections'] = connections
    
    return workflow


def apply_env_vars(workflow: Dict) -> Dict:
    """ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’ç’°å¢ƒå¤‰æ•°ã«ç½®æ›"""
    workflow_str = json.dumps(workflow, ensure_ascii=False)
    
    for pattern, replacement in ENV_VAR_PATTERNS:
        workflow_str = re.sub(pattern, replacement, workflow_str)
    
    return json.loads(workflow_str)


def mark_python_migration_nodes(workflow: Dict) -> Dict:
    """Pythonç§»è¡Œå€™è£œãƒãƒ¼ãƒ‰ã‚’ãƒãƒ¼ã‚¯"""
    workflow = copy.deepcopy(workflow)
    nodes = workflow.get('nodes', [])
    
    for node in nodes:
        # Codeãƒãƒ¼ãƒ‰ã®å†…å®¹ã‚’ãƒã‚§ãƒƒã‚¯
        if node.get('type') == 'n8n-nodes-base.code':
            js_code = node.get('parameters', {}).get('jsCode', '')
            
            # è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã‚’å«ã‚€ã‹åˆ¤å®š
            calc_indicators = [
                'profit',
                'margin',
                'tariff',
                'shipping',
                'ddp',
                'DDP',
                'exchangeRate',
                'exchange_rate',
            ]
            
            if any(ind in js_code for ind in calc_indicators):
                notes = node.get('notes', '') or ''
                if PYTHON_MIGRATION_MARKER not in notes:
                    node['notes'] = f'{notes}\n{PYTHON_MIGRATION_MARKER}'.strip()
    
    workflow['nodes'] = nodes
    return workflow


def apply_security_settings(workflow: Dict) -> Dict:
    """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šã‚’é©ç”¨"""
    workflow = copy.deepcopy(workflow)
    
    settings = workflow.get('settings', {})
    
    # æˆåŠŸæ™‚ã®å®Ÿè¡Œãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ãªã„ï¼ˆãƒ¡ãƒ¢ãƒªç¯€ç´„ï¼‰
    settings['saveDataSuccessExecution'] = 'none'
    
    # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    settings['saveDataErrorExecution'] = 'all'
    
    # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
    if 'executionTimeout' not in settings:
        settings['executionTimeout'] = 600
    
    workflow['settings'] = settings
    
    return workflow


def add_fortress_tags(workflow: Dict) -> Dict:
    """è¦å¡åŒ–ã‚¿ã‚°ã‚’è¿½åŠ """
    workflow = copy.deepcopy(workflow)
    
    tags = workflow.get('tags', [])
    tag_names = [t.get('name', '') for t in tags]
    
    if 'FORTRESS' not in tag_names:
        tags.append({
            'name': 'FORTRESS',
            'color': '#dc143c'
        })
    
    if 'V6-ENHANCED' not in tag_names:
        tags.append({
            'name': 'V6-ENHANCED',
            'color': '#00bfff'
        })
    
    workflow['tags'] = tags
    
    return workflow


def convert_workflow(workflow: Dict, options: Dict = None) -> Dict:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’è¦å¡åŒ–å¤‰æ›"""
    options = options or {}
    
    # 1. HMACæ¤œè¨¼ãƒãƒ¼ãƒ‰æŒ¿å…¥
    if options.get('insert_hmac', True):
        workflow = insert_hmac_verify_node(workflow)
    
    # 2. ç’°å¢ƒå¤‰æ•°åŒ–
    if options.get('env_vars', True):
        workflow = apply_env_vars(workflow)
    
    # 3. Pythonç§»è¡Œå€™è£œãƒãƒ¼ã‚¯
    if options.get('mark_python', True):
        workflow = mark_python_migration_nodes(workflow)
    
    # 4. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
    if options.get('security', True):
        workflow = apply_security_settings(workflow)
    
    # 5. ã‚¿ã‚°è¿½åŠ 
    if options.get('tags', True):
        workflow = add_fortress_tags(workflow)
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
    workflow['_fortress_converted'] = True
    workflow['_fortress_version'] = '1.0.0'
    workflow['_fortress_timestamp'] = datetime.utcnow().isoformat()
    
    return workflow


def convert_file(input_path: str, output_path: str, options: Dict = None) -> bool:
    """ãƒ•ã‚¡ã‚¤ãƒ«å˜ä½ã®å¤‰æ›"""
    try:
        with open(input_path, 'r', encoding='utf-8') as f:
            workflow = json.load(f)
        
        converted = convert_workflow(workflow, options)
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(converted, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        print(f'âŒ å¤‰æ›ã‚¨ãƒ©ãƒ¼: {input_path} - {e}')
        return False


def convert_directory(input_dir: str, output_dir: str, options: Dict = None) -> Dict:
    """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€æ‹¬å¤‰æ›"""
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    
    results = {
        'total': 0,
        'success': 0,
        'failed': 0,
        'skipped': 0,
        'errors': [],
    }
    
    # å…¨JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    json_files = list(input_path.rglob('*.json'))
    results['total'] = len(json_files)
    
    print(f'\nğŸ“‚ å¤‰æ›å¯¾è±¡: {results["total"]} ãƒ•ã‚¡ã‚¤ãƒ«')
    print(f'å…¥åŠ›: {input_dir}')
    print(f'å‡ºåŠ›: {output_dir}')
    print('=' * 50)
    
    for json_file in json_files:
        relative_path = json_file.relative_to(input_path)
        output_file = output_path / relative_path
        
        # ãƒã‚¹ã‚¿ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚„embedded_logicã¯ã‚¹ã‚­ãƒƒãƒ—
        if json_file.name in ['UI_CONFIG_MASTER.json', 'embedded_logic.json']:
            results['skipped'] += 1
            print(f'â­ï¸  ã‚¹ã‚­ãƒƒãƒ—: {relative_path}')
            continue
        
        print(f'ğŸ”„ å¤‰æ›ä¸­: {relative_path}', end='... ')
        
        if convert_file(str(json_file), str(output_file), options):
            results['success'] += 1
            print('âœ…')
        else:
            results['failed'] += 1
            results['errors'].append(str(relative_path))
            print('âŒ')
    
    return results


def validate_json_files(directory: str) -> Dict:
    """JSONãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹æ–‡æ¤œè¨¼"""
    path = Path(directory)
    json_files = list(path.rglob('*.json'))
    
    results = {
        'total': len(json_files),
        'valid': 0,
        'invalid': 0,
        'errors': [],
    }
    
    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                json.load(f)
            results['valid'] += 1
        except json.JSONDecodeError as e:
            results['invalid'] += 1
            results['errors'].append({
                'file': str(json_file),
                'error': str(e),
            })
    
    return results


# ======================
# CLI
# ======================

def main():
    parser = argparse.ArgumentParser(
        description='N3 Empire OS JSONè¦å¡åŒ–å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆ'
    )
    
    subparsers = parser.add_subparsers(dest='command', help='ã‚³ãƒãƒ³ãƒ‰')
    
    # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›
    convert_parser = subparsers.add_parser('convert', help='å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›')
    convert_parser.add_argument('input', help='å…¥åŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«')
    convert_parser.add_argument('output', help='å‡ºåŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«')
    
    # ãƒãƒƒãƒå¤‰æ›
    batch_parser = subparsers.add_parser('batch', help='ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€æ‹¬å¤‰æ›')
    batch_parser.add_argument('input_dir', help='å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    batch_parser.add_argument('output_dir', help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    
    # æ¤œè¨¼
    validate_parser = subparsers.add_parser('validate', help='JSONæ§‹æ–‡æ¤œè¨¼')
    validate_parser.add_argument('directory', help='æ¤œè¨¼å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    
    args = parser.parse_args()
    
    if args.command == 'convert':
        success = convert_file(args.input, args.output)
        sys.exit(0 if success else 1)
    
    elif args.command == 'batch':
        results = convert_directory(args.input_dir, args.output_dir)
        
        print('\n' + '=' * 50)
        print('ğŸ“Š å¤‰æ›çµæœã‚µãƒãƒªãƒ¼')
        print('=' * 50)
        print(f'  åˆè¨ˆ: {results["total"]} ãƒ•ã‚¡ã‚¤ãƒ«')
        print(f'  æˆåŠŸ: {results["success"]} ãƒ•ã‚¡ã‚¤ãƒ«')
        print(f'  å¤±æ•—: {results["failed"]} ãƒ•ã‚¡ã‚¤ãƒ«')
        print(f'  ã‚¹ã‚­ãƒƒãƒ—: {results["skipped"]} ãƒ•ã‚¡ã‚¤ãƒ«')
        
        if results['errors']:
            print('\nâŒ å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ«:')
            for err in results['errors']:
                print(f'  - {err}')
        
        sys.exit(0 if results['failed'] == 0 else 1)
    
    elif args.command == 'validate':
        results = validate_json_files(args.directory)
        
        print('\n' + '=' * 50)
        print('ğŸ“Š æ¤œè¨¼çµæœ')
        print('=' * 50)
        print(f'  åˆè¨ˆ: {results["total"]} ãƒ•ã‚¡ã‚¤ãƒ«')
        print(f'  æœ‰åŠ¹: {results["valid"]} ãƒ•ã‚¡ã‚¤ãƒ«')
        print(f'  ç„¡åŠ¹: {results["invalid"]} ãƒ•ã‚¡ã‚¤ãƒ«')
        
        if results['errors']:
            print('\nâŒ ç„¡åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«:')
            for err in results['errors']:
                print(f'  - {err["file"]}')
                print(f'    ã‚¨ãƒ©ãƒ¼: {err["error"]}')
        
        sys.exit(0 if results['invalid'] == 0 else 1)
    
    else:
        # å¼•æ•°ãªã—ã§å‘¼ã³å‡ºã•ã‚ŒãŸå ´åˆ
        if len(sys.argv) == 3:
            # å¾Œæ–¹äº’æ›: python script.py input output
            success = convert_file(sys.argv[1], sys.argv[2])
            sys.exit(0 if success else 1)
        else:
            parser.print_help()
            sys.exit(1)


if __name__ == '__main__':
    main()
